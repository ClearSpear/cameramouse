{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handclassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO93H16KrhxTFxYmEX367cF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClearSpear/cameramouse/blob/master/handclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHtuoLOBo9BZ",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive to save files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh64hvweo8Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxtqfhgpCPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcGJ9Asq6KJB",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoTcRjtq6JUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHJW36tapNa5",
        "colab_type": "text"
      },
      "source": [
        "## Create labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHMi5kx9xn4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def get_label_num(s):\n",
        "  if s == 'fist':\n",
        "    return 0\n",
        "  if s == 'palm':\n",
        "    return 1\n",
        "\n",
        "paths = []\n",
        "labels = []\n",
        "\n",
        "#data_dir = './tinyhand'\n",
        "data_dir = '/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand'\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    dirs.sort()\n",
        "    for d in dirs:\n",
        "      data_subdir = os.path.join(root, d)\n",
        "      images = [os.path.join(data_subdir, name) for name in os.listdir(data_subdir) if os.path.isfile(os.path.join(data_subdir, name))]\n",
        "      num_images = len(images)\n",
        "      label_num = data_subdir[-4:]\n",
        "      print(data_subdir, str(num_images))\n",
        "      labels += [label_num] * num_images\n",
        "      paths += images\n",
        "\n",
        "data_dict = {'img_path':paths,'label':labels}\n",
        "data_df = pd.DataFrame(data_dict)\n",
        "print(data_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7VFAbWTD6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df.to_csv(\"tinyhand_image_labels.df\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVdzuhH9rwJf",
        "colab_type": "text"
      },
      "source": [
        "## Read in labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MGqndbNrxeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_df = pd.read_csv(\"tinyhand_image_labels.df\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hn-shCrr2n9",
        "colab_type": "text"
      },
      "source": [
        "## Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyQ6mbJ_xvfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    data_df,\n",
        "    directory=None,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    data_df,\n",
        "    directory=None,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSj7BNvHKYe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(val_generator)\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfP0Am5VsYmG",
        "colab_type": "text"
      },
      "source": [
        "## Create labels textfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP1spgnmKakz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('hand_labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXJeQpIKKeXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat hand_labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKb1uwo_5U9c",
        "colab_type": "text"
      },
      "source": [
        "## Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxs2sm955X_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ozhtw5d6_n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QgfOhjps3LM",
        "colab_type": "text"
      },
      "source": [
        "If using saved weights, load them in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24fgm-Ps5oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights\n",
        "model.load_weights(\"weights.best.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1oLj7Wss6FP",
        "colab_type": "text"
      },
      "source": [
        "Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg1q2kzz7DB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F423bIuiss1P",
        "colab_type": "text"
      },
      "source": [
        "Setup checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1h3yOzNsjPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doD9ZbiF7EXr",
        "colab_type": "text"
      },
      "source": [
        "View the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy-f2M5k7Fie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "print('Number of trainable weights = {}'.format(len(model.trainable_weights)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzcxQZwh78vx",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4jfDW7e7W8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                              epochs=2, \n",
        "                              callbacks=callbacks_list, \n",
        "                              validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_KPR-w8IE_",
        "colab_type": "text"
      },
      "source": [
        "View the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-nCj8x8Jkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnzsavfj9UPM",
        "colab_type": "text"
      },
      "source": [
        "## Convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTh9kcVt9feo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A generator that provides a representative dataset\n",
        "def representative_data_gen():\n",
        "  dataset_list = tf.data.Dataset.list_files('/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/*/*/*')\n",
        "  for i in range(100):\n",
        "    image = next(iter(dataset_list))\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]\n",
        "\n",
        "saved_keras_model = 'model.h5'\n",
        "model.save(saved_keras_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(saved_keras_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# These set the input and output tensors to uint8\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "# And this sets the representative dataset so we can quantize the activations\n",
        "converter.representative_dataset = representative_data_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dOdNgdl9jYE",
        "colab_type": "text"
      },
      "source": [
        "## Look at accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JunR_079lM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_images, batch_labels = next(val_generator)\n",
        "\n",
        "logits = model(batch_images)\n",
        "prediction = np.argmax(logits, axis=1)\n",
        "truth = np.argmax(batch_labels, axis=1)\n",
        "\n",
        "keras_accuracy = tf.keras.metrics.Accuracy()\n",
        "keras_accuracy(prediction, truth)\n",
        "\n",
        "print(\"Raw model accuracy: {:.3%}\".format(keras_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mDTSwRy9ncS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_input_tensor(interpreter, input):\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  tensor_index = input_details['index']\n",
        "  scale, zero_point = input_details['quantization']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  # The input tensor data must be uint8: within [0, 255].\n",
        "  input_tensor[:, :] = np.uint8(input / scale + zero_point)\n",
        "\n",
        "def classify_image(interpreter, input):\n",
        "  set_input_tensor(interpreter, input)\n",
        "  interpreter.invoke()\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "  output = interpreter.get_tensor(output_details['index'])\n",
        "  # Because the model is quantized (uint8 data), we dequantize the results\n",
        "  scale, zero_point = output_details['quantization']\n",
        "  output = scale * (output - zero_point)\n",
        "  top_1 = np.argmax(output)\n",
        "  return top_1\n",
        "\n",
        "interpreter = tf.lite.Interpreter('mobilenet_v2_1.0_224_quant.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Collect all inference predictions in a list\n",
        "batch_prediction = []\n",
        "batch_truth = np.argmax(batch_labels, axis=1)\n",
        "\n",
        "for i in range(len(batch_images)):\n",
        "  prediction = classify_image(interpreter, batch_images[i])\n",
        "  batch_prediction.append(prediction)\n",
        "\n",
        "# Compare all predictions to the ground truth\n",
        "tflite_accuracy = tf.keras.metrics.Accuracy()\n",
        "tflite_accuracy(batch_prediction, batch_truth)\n",
        "print(\"Quant TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebqbz7y39tqe",
        "colab_type": "text"
      },
      "source": [
        "## Compile for edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ORnEXb90aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTWH1KYd93Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! edgetpu_compiler mobilenet_v2_1.0_224_quant.tflite"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}