{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handclassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rHJW36tapNa5",
        "HfP0Am5VsYmG"
      ],
      "authorship_tag": "ABX9TyOoSWmh7+Yj/o6F0XzPGiZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClearSpear/cameramouse/blob/master/handclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHtuoLOBo9BZ",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive to save files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh64hvweo8Pd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "edf69dcd-704b-4989-a932-996382597109"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxtqfhgpCPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8123c367-cfa1-4f4d-efd9-e4b84bc496dd"
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcGJ9Asq6KJB",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoTcRjtq6JUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beeb7776-b0e5-41e8-e82a-a0296fcff2f4"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHJW36tapNa5",
        "colab_type": "text"
      },
      "source": [
        "## Create labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHMi5kx9xn4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26fcac90-f8f8-4293-ba5a-1429b2eb3f48"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def get_label_num(s):\n",
        "  if s == 'fist':\n",
        "    return 0\n",
        "  if s == 'palm':\n",
        "    return 1\n",
        "\n",
        "paths = []\n",
        "labels = []\n",
        "\n",
        "#data_dir = './tinyhand'\n",
        "data_dir = '/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand'\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    dirs.sort()\n",
        "    for d in dirs:\n",
        "      data_subdir = os.path.join(root, d)\n",
        "      images = [os.path.join(data_subdir, name) for name in os.listdir(data_subdir) if os.path.isfile(os.path.join(data_subdir, name))]\n",
        "      num_images = len(images)\n",
        "      label_num = data_subdir[-4:]\n",
        "      print(data_subdir, str(num_images))\n",
        "      labels += [label_num] * num_images\n",
        "      paths += images\n",
        "\n",
        "data_dict = {'img_path':paths,'label':labels}\n",
        "data_df = pd.DataFrame(data_dict)\n",
        "print(data_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/aishwary 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alberto 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alfredo 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana_m 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/arturo 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_ca 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_r 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carmen 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cristina 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/esther 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/federico 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/fili 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/javier 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jesus 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jose_luis 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lara 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lorena 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marie 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marta 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/mateo 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/rafa 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raquel 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raul 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/richard 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/samira 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/sergio 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas_2 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/vir 0\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/aishwary/fist 1832\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/aishwary/palm 1821\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alberto/fist 447\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alberto/palm 426\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alfredo/fist 421\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/alfredo/palm 416\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana/fist 426\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana/palm 424\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana_m/fist 249\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/ana_m/palm 251\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/arturo/fist 431\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/arturo/palm 436\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c/fist 429\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c/palm 409\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c_2/fist 1823\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_c_2/palm 1835\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_ca/fist 1972\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_ca/palm 1845\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_r/fist 412\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carlos_r/palm 438\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carmen/fist 1938\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/carmen/palm 1855\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar/fist 431\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar/palm 420\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar_2/fist 1837\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cesar_2/palm 1849\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cristina/fist 395\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/cristina/palm 424\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani/fist 251\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani/palm 247\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani_2/fist 1833\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/dani_2/palm 1842\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/esther/fist 439\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/esther/palm 406\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/federico/fist 411\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/federico/palm 398\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/fili/fist 416\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/fili/palm 415\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/javier/fist 1907\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/javier/palm 1857\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jesus/fist 436\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jesus/palm 433\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jose_luis/fist 243\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/jose_luis/palm 246\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lara/fist 1837\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lara/palm 1929\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lorena/fist 245\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/lorena/palm 234\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marie/fist 1822\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marie/palm 1835\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marta/fist 1888\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/marta/palm 1823\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/mateo/fist 1841\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/mateo/palm 1829\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo/fist 431\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo/palm 440\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo_2/fist 1878\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/pablo_2/palm 1828\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/rafa/fist 421\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/rafa/palm 375\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raquel/fist 442\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raquel/palm 421\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raul/fist 444\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/raul/palm 410\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/richard/fist 1818\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/richard/palm 1828\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/samira/fist 248\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/samira/palm 250\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/sergio/fist 456\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/sergio/palm 441\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana/fist 251\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana/palm 252\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana_2/fist 1830\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/susana_2/palm 1825\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas/fist 416\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas/palm 413\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas_2/fist 1875\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/tomas_2/palm 1842\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/vir/fist 437\n",
            "/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/vir/palm 402\n",
            "                                                img_path label\n",
            "0      /content/gdrive/My Drive/Stanford/EE292D/proje...  fist\n",
            "1      /content/gdrive/My Drive/Stanford/EE292D/proje...  fist\n",
            "2      /content/gdrive/My Drive/Stanford/EE292D/proje...  fist\n",
            "3      /content/gdrive/My Drive/Stanford/EE292D/proje...  fist\n",
            "4      /content/gdrive/My Drive/Stanford/EE292D/proje...  fist\n",
            "...                                                  ...   ...\n",
            "74624  /content/gdrive/My Drive/Stanford/EE292D/proje...  palm\n",
            "74625  /content/gdrive/My Drive/Stanford/EE292D/proje...  palm\n",
            "74626  /content/gdrive/My Drive/Stanford/EE292D/proje...  palm\n",
            "74627  /content/gdrive/My Drive/Stanford/EE292D/proje...  palm\n",
            "74628  /content/gdrive/My Drive/Stanford/EE292D/proje...  palm\n",
            "\n",
            "[74629 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7VFAbWTD6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df.to_csv(\"tinyhand_image_labels.df\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVdzuhH9rwJf",
        "colab_type": "text"
      },
      "source": [
        "## Read in labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MGqndbNrxeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_df = pd.read_csv(\"tinyhand_image_labels.df\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hn-shCrr2n9",
        "colab_type": "text"
      },
      "source": [
        "## Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyQ6mbJ_xvfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5fc5b602-9bb3-4eda-d64c-3f3d93a8ef2a"
      },
      "source": [
        "IMAGE_SIZE = 300\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    data_df,\n",
        "    directory=None,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    data_df,\n",
        "    directory=None,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 59704 validated image filenames belonging to 2 classes.\n",
            "Found 14925 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSj7BNvHKYe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e0680e1-28b3-489c-d849-583a4bea56cc"
      },
      "source": [
        "image_batch, label_batch = next(val_generator)\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 300, 300, 3), (64, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfP0Am5VsYmG",
        "colab_type": "text"
      },
      "source": [
        "## Create labels textfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP1spgnmKakz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca4c6f65-df8b-4463-a37e-906c7d4bbf42"
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('hand_labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fist': 0, 'palm': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXJeQpIKKeXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f048b0f1-8339-4f30-b6b9-11a23a534e6a"
      },
      "source": [
        "!cat hand_labels.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fist\n",
            "palm"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKb1uwo_5U9c",
        "colab_type": "text"
      },
      "source": [
        "## Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxs2sm955X_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5538416a-849a-47dc-f3e6-611585614eca"
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ozhtw5d6_n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QgfOhjps3LM",
        "colab_type": "text"
      },
      "source": [
        "If using saved weights, load them in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24fgm-Ps5oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights\n",
        "model.load_weights(\"weights.best.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1oLj7Wss6FP",
        "colab_type": "text"
      },
      "source": [
        "Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg1q2kzz7DB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F423bIuiss1P",
        "colab_type": "text"
      },
      "source": [
        "Setup checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1h3yOzNsjPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "310dfa78-4501-4932-e6ee-e34951711fc6"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doD9ZbiF7EXr",
        "colab_type": "text"
      },
      "source": [
        "View the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy-f2M5k7Fie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "cdee5425-03ee-40ff-8ca4-dbfff7b31ab0"
      },
      "source": [
        "model.summary()\n",
        "print('Number of trainable weights = {}'.format(len(model.trainable_weights)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 5, 5, 32)          368672    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 2,626,722\n",
            "Trainable params: 2,231,330\n",
            "Non-trainable params: 395,392\n",
            "_________________________________________________________________\n",
            "Number of trainable weights = 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzcxQZwh78vx",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4jfDW7e7W8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "19ca276e-bc75-4c5d-b5da-b815bdd35a12"
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                              epochs=2, \n",
        "                              callbacks=callbacks_list, \n",
        "                              validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "932/933 [============================>.] - ETA: 15s - loss: 0.0747 - acc: 0.9717Epoch 1/2\n",
            "234/933 [======>.......................] - ETA: 2:54:00 - loss: 0.1419 - acc: 0.9764\n",
            "Epoch 00001: val_acc improved from -inf to 0.97642, saving model to weights.best.hdf5\n",
            "933/933 [==============================] - 17951s 19s/step - loss: 0.0746 - acc: 0.9717 - val_loss: 0.1419 - val_acc: 0.9764\n",
            "Epoch 2/2\n",
            "932/933 [============================>.] - ETA: 13s - loss: 0.0014 - acc: 0.9996Epoch 1/2\n",
            "234/933 [======>.......................] - ETA: 2:48:33 - loss: 0.0390 - acc: 0.9890\n",
            "Epoch 00002: val_acc improved from 0.97642 to 0.98901, saving model to weights.best.hdf5\n",
            "933/933 [==============================] - 16311s 17s/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0390 - val_acc: 0.9890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_KPR-w8IE_",
        "colab_type": "text"
      },
      "source": [
        "View the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-nCj8x8Jkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "5cd6464d-fa56-43cb-f989-0e92fa4fa9a1"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ec16c8d7061c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnzsavfj9UPM",
        "colab_type": "text"
      },
      "source": [
        "## Convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTh9kcVt9feo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c6b4d350-4d07-477d-efa7-aa39b4c696dd"
      },
      "source": [
        "# A generator that provides a representative dataset\n",
        "def representative_data_gen():\n",
        "  dataset_list = tf.data.Dataset.list_files('/content/gdrive/My Drive/Stanford/EE292D/project/colab_handclassification/tinyhand/*/*/*')\n",
        "  for i in range(100):\n",
        "    image = next(iter(dataset_list))\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]\n",
        "\n",
        "saved_keras_model = 'model.h5'\n",
        "model.save(saved_keras_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(saved_keras_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# These set the input and output tensors to uint8\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "# And this sets the representative dataset so we can quantize the activations\n",
        "converter.representative_dataset = representative_data_gen\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb6f27c2f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb6f27c2f28> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dOdNgdl9jYE",
        "colab_type": "text"
      },
      "source": [
        "## Look at accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JunR_079lM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0246a3d5-2a1f-4de1-e2d5-cbf2a235fd02"
      },
      "source": [
        "batch_images, batch_labels = next(val_generator)\n",
        "\n",
        "logits = model(batch_images)\n",
        "prediction = np.argmax(logits, axis=1)\n",
        "truth = np.argmax(batch_labels, axis=1)\n",
        "\n",
        "keras_accuracy = tf.keras.metrics.Accuracy()\n",
        "keras_accuracy(prediction, truth)\n",
        "\n",
        "print(\"Raw model accuracy: {:.3%}\".format(keras_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw model accuracy: 96.875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mDTSwRy9ncS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "291a72f6-c985-4867-9201-9f1bc1132860"
      },
      "source": [
        "def set_input_tensor(interpreter, input):\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  tensor_index = input_details['index']\n",
        "  scale, zero_point = input_details['quantization']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  # The input tensor data must be uint8: within [0, 255].\n",
        "  input_tensor[:, :] = np.uint8(input / scale + zero_point)\n",
        "\n",
        "def classify_image(interpreter, input):\n",
        "  set_input_tensor(interpreter, input)\n",
        "  interpreter.invoke()\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "  output = interpreter.get_tensor(output_details['index'])\n",
        "  # Because the model is quantized (uint8 data), we dequantize the results\n",
        "  scale, zero_point = output_details['quantization']\n",
        "  output = scale * (output - zero_point)\n",
        "  top_1 = np.argmax(output)\n",
        "  return top_1\n",
        "\n",
        "interpreter = tf.lite.Interpreter('mobilenet_v2_1.0_224_quant.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Collect all inference predictions in a list\n",
        "batch_prediction = []\n",
        "batch_truth = np.argmax(batch_labels, axis=1)\n",
        "\n",
        "for i in range(len(batch_images)):\n",
        "  prediction = classify_image(interpreter, batch_images[i])\n",
        "  batch_prediction.append(prediction)\n",
        "\n",
        "# Compare all predictions to the ground truth\n",
        "tflite_accuracy = tf.keras.metrics.Accuracy()\n",
        "tflite_accuracy(batch_prediction, batch_truth)\n",
        "print(\"Quant TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quant TF Lite accuracy: 96.875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebqbz7y39tqe",
        "colab_type": "text"
      },
      "source": [
        "## Compile for edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ORnEXb90aO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23e4741a-9ae1-466c-ae81-2de0575e17bb"
      },
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   653  100   653    0     0  22517      0 --:--:-- --:--:-- --:--:-- 22517\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:6 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [1,277 B]\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [162 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [856 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,387 kB]\n",
            "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,830 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,230 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [933 kB]\n",
            "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [882 kB]\n",
            "Fetched 7,619 kB in 4s (2,025 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libedgetpu1-std\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler libedgetpu1-std\n",
            "0 upgraded, 2 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 4,998 kB of archives.\n",
            "After this operation, 18.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 libedgetpu1-std amd64 14.0 [306 kB]\n",
            "Get:2 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 14.0 [4,692 kB]\n",
            "Fetched 4,998 kB in 1s (4,635 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libedgetpu1-std:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libedgetpu1-std_14.0_amd64.deb ...\n",
            "Unpacking libedgetpu1-std:amd64 (14.0) ...\n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "Preparing to unpack .../edgetpu-compiler_14.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (14.0) ...\n",
            "Setting up libedgetpu1-std:amd64 (14.0) ...\n",
            "Setting up edgetpu-compiler (14.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTWH1KYd93Yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "e8b510de-d0aa-4ece-b056-3d3088b087cb"
      },
      "source": [
        "! edgetpu_compiler mobilenet_v2_1.0_224_quant.tflite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 2.1.302470888\n",
            "\n",
            "Model compiled successfully in 544 ms.\n",
            "\n",
            "Input model: mobilenet_v2_1.0_224_quant.tflite\n",
            "Input size: 2.93MiB\n",
            "Output model: mobilenet_v2_1.0_224_quant_edgetpu.tflite\n",
            "Output size: 3.11MiB\n",
            "On-chip memory used for caching model parameters: 3.33MiB\n",
            "On-chip memory remaining for caching model parameters: 4.39MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 73\n",
            "Operation log: mobilenet_v2_1.0_224_quant_edgetpu.log\n",
            "See the operation log file for individual operation details.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}